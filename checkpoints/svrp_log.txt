2025-04-09 19:22:55,608 [INFO] Starting SVRP-RL with Namespace(num_nodes=20, num_vehicles=1, capacity=50.0, a_ratio=0.6, b_ratio=0.2, gamma_ratio=0.2, weather_dim=3, fixed_customers=False, embedding_dim=128, epochs=100, batch_size=32, lr=0.0001, baseline_lr=0.001, entropy_weight=0.01, max_steps=100, inference='beam', num_samples=16, beam_width=3, test_size=100, cuda=False, seed=42, save_dir='checkpoints', load_model=None, test=False, log_interval=10, save_interval=20, reoptimization=False)
2025-04-09 19:22:55,609 [INFO] Using device: cpu
2025-04-09 19:22:55,609 [INFO] Customer features dimension: 24
2025-04-09 19:22:55,609 [INFO] Vehicle features dimension: 2
2025-04-09 19:22:57,881 [INFO] Starting training for 100 epochs
2025-04-09 19:24:23,744 [INFO] Epoch 10/100 | Reward: -69.6718 | Policy Loss: -1698.0011 | Baseline Loss: 27483.0938 | Time: 8.41s
2025-04-09 19:25:48,638 [INFO] Epoch 20/100 | Reward: -70.1642 | Policy Loss: -1425.5339 | Baseline Loss: 20595.0859 | Time: 8.34s
2025-04-09 19:25:48,658 [INFO] Saved model to checkpoints\model_epoch_20
2025-04-09 19:25:49,037 [INFO] Instance 1: Cost = 7.2346, Routes = [[12, 0, 7]]
2025-04-09 19:25:50,638 [INFO] Instance 2: Cost = 6.9318, Routes = [[12, 1, 11]]
2025-04-09 19:25:50,973 [INFO] Instance 3: Cost = 6.9959, Routes = [[12, 6, 7]]
2025-04-09 19:25:51,297 [INFO] Instance 4: Cost = 6.9491, Routes = [[3, 9, 6]]
2025-04-09 19:25:51,633 [INFO] Instance 5: Cost = 7.2100, Routes = [[3, 11, 19]]
2025-04-09 19:25:53,322 [INFO] Evaluation completed. Mean reward: -6.9788
2025-04-09 19:25:53,322 [INFO] Test reward: -6.9788
2025-04-09 19:27:20,262 [INFO] Epoch 30/100 | Reward: -70.6680 | Policy Loss: -855.2347 | Baseline Loss: 11686.9375 | Time: 8.47s
2025-04-09 19:28:44,850 [INFO] Epoch 40/100 | Reward: -72.6325 | Policy Loss: -140.6836 | Baseline Loss: 8591.2998 | Time: 8.36s
2025-04-09 19:28:44,867 [INFO] Saved model to checkpoints\model_epoch_40
2025-04-09 19:28:45,205 [INFO] Instance 1: Cost = 7.1705, Routes = [[18, 4, 8]]
2025-04-09 19:28:45,837 [INFO] Instance 2: Cost = 7.4493, Routes = [[4, 17, 12]]
2025-04-09 19:28:46,167 [INFO] Instance 3: Cost = 8.1978, Routes = [[13, 19, 6, 0]]
2025-04-09 19:28:46,502 [INFO] Instance 4: Cost = 7.4548, Routes = [[13, 5, 11]]
2025-04-09 19:28:46,841 [INFO] Instance 5: Cost = 7.3961, Routes = [[13, 17, 2]]
2025-04-09 19:28:48,484 [INFO] Evaluation completed. Mean reward: -7.4886
2025-04-09 19:28:48,484 [INFO] Test reward: -7.4886
2025-04-09 19:30:13,295 [INFO] Epoch 50/100 | Reward: -70.6034 | Policy Loss: -65.8344 | Baseline Loss: 8153.4746 | Time: 8.37s
2025-04-09 19:31:37,514 [INFO] Epoch 60/100 | Reward: -69.1068 | Policy Loss: -273.4041 | Baseline Loss: 6913.2886 | Time: 8.27s
2025-04-09 19:31:37,530 [INFO] Saved model to checkpoints\model_epoch_60
2025-04-09 19:31:37,868 [INFO] Instance 1: Cost = 8.0049, Routes = [[19, 0, 0, 0]]
2025-04-09 19:31:38,499 [INFO] Instance 2: Cost = 8.1171, Routes = [[17, 0, 0, 0]]
2025-04-09 19:31:38,875 [INFO] Instance 3: Cost = 7.9928, Routes = [[12, 0, 0, 0]]
2025-04-09 19:31:39,262 [INFO] Instance 4: Cost = 8.2004, Routes = [[16, 0, 0, 0]]
2025-04-09 19:31:39,614 [INFO] Instance 5: Cost = 8.0125, Routes = [[8, 7, 11, 0]]
2025-04-09 19:31:41,350 [INFO] Evaluation completed. Mean reward: -7.9800
2025-04-09 19:31:41,351 [INFO] Test reward: -7.9800
2025-04-09 19:33:19,312 [INFO] Epoch 70/100 | Reward: -70.2309 | Policy Loss: -292.4871 | Baseline Loss: 7233.0952 | Time: 10.52s
2025-04-09 19:34:53,281 [INFO] Epoch 80/100 | Reward: -71.0810 | Policy Loss: -210.1408 | Baseline Loss: 7615.4980 | Time: 9.07s
2025-04-09 19:34:53,286 [INFO] Saved model to checkpoints\model_epoch_80
2025-04-09 19:34:53,636 [INFO] Instance 1: Cost = 7.9715, Routes = [[6, 11, 0, 0]]
2025-04-09 19:34:54,313 [INFO] Instance 2: Cost = 7.7166, Routes = [[8, 0, 0, 0]]
2025-04-09 19:34:54,681 [INFO] Instance 3: Cost = 7.9501, Routes = [[7, 0, 0, 0]]
2025-04-09 19:34:55,054 [INFO] Instance 4: Cost = 7.6903, Routes = [[8, 0, 0, 0]]
2025-04-09 19:34:55,409 [INFO] Instance 5: Cost = 7.7613, Routes = [[7, 0, 0, 0]]
2025-04-09 19:34:57,184 [INFO] Evaluation completed. Mean reward: -7.8177
2025-04-09 19:34:57,184 [INFO] Test reward: -7.8177
2025-04-09 19:36:32,835 [INFO] Epoch 90/100 | Reward: -71.4202 | Policy Loss: -279.1256 | Baseline Loss: 7323.3359 | Time: 8.73s
2025-04-09 19:37:59,788 [INFO] Epoch 100/100 | Reward: -72.0833 | Policy Loss: -318.1506 | Baseline Loss: 7889.5171 | Time: 8.97s
2025-04-09 19:37:59,805 [INFO] Saved model to checkpoints\model_epoch_100
2025-04-09 19:38:00,188 [INFO] Instance 1: Cost = 6.8979, Routes = [[9, 10, 0, 0]]
2025-04-09 19:38:00,891 [INFO] Instance 2: Cost = 6.7242, Routes = [[15, 7, 0, 0]]
2025-04-09 19:38:01,227 [INFO] Instance 3: Cost = 7.6798, Routes = [[7, 0, 0, 0]]
2025-04-09 19:38:01,565 [INFO] Instance 4: Cost = 6.4743, Routes = [[9, 10, 0, 0]]
2025-04-09 19:38:01,907 [INFO] Instance 5: Cost = 6.8305, Routes = [[7, 0, 0, 0]]
2025-04-09 19:38:03,582 [INFO] Evaluation completed. Mean reward: -7.1242
2025-04-09 19:38:03,582 [INFO] Test reward: -7.1242
2025-04-09 19:38:03,586 [INFO] Saved final model to checkpoints\model_final
2025-04-09 19:38:04,118 [INFO] Training completed
2025-04-09 19:38:04,119 [INFO] Evaluating model with beam inference strategy
2025-04-09 19:38:04,424 [INFO] Instance 1: Cost = 6.6273, Routes = [[7, 0, 0, 0]]
2025-04-09 19:38:05,028 [INFO] Instance 2: Cost = 7.5872, Routes = [[5, 0, 0, 0]]
2025-04-09 19:38:05,372 [INFO] Instance 3: Cost = 7.5309, Routes = [[2, 0, 0, 0]]
2025-04-09 19:38:05,714 [INFO] Instance 4: Cost = 7.4230, Routes = [[0, 0, 0, 0]]
2025-04-09 19:38:06,052 [INFO] Instance 5: Cost = 7.1605, Routes = [[5, 0, 0, 0]]
2025-04-09 19:38:38,020 [INFO] Evaluation completed. Mean reward: -7.0835
2025-04-09 19:38:38,021 [INFO] Final evaluation - Mean reward: -7.0835
2025-04-09 20:41:59,024 [INFO] Starting SVRP-RL with Namespace(num_nodes=20, num_vehicles=1, capacity=50.0, a_ratio=0.6, b_ratio=0.2, gamma_ratio=0.2, weather_dim=3, fixed_customers=False, embedding_dim=128, epochs=100, batch_size=32, lr=0.0001, baseline_lr=0.001, entropy_weight=0.01, max_steps=100, inference='beam', num_samples=16, beam_width=3, test_size=100, cuda=False, seed=42, save_dir='checkpoints', load_model='checkpoints/model_final', test=True, log_interval=10, save_interval=20, reoptimization=False)
2025-04-09 20:41:59,025 [INFO] Using device: cpu
2025-04-09 20:41:59,025 [INFO] Customer features dimension: 24
2025-04-09 20:41:59,025 [INFO] Vehicle features dimension: 2
2025-04-09 20:42:01,634 [INFO] Loaded model from checkpoints/model_final
2025-04-09 20:42:01,634 [INFO] Evaluating model with beam inference strategy
2025-04-09 20:42:02,075 [INFO] Instance 1: Cost = 6.8610, Routes = [[9, 6, 0, 0]]
2025-04-09 20:42:03,005 [INFO] Instance 2: Cost = 7.6485, Routes = [[0, 0, 0, 0]]
2025-04-09 20:42:03,352 [INFO] Instance 3: Cost = 6.7028, Routes = [[18, 7, 0, 0]]
2025-04-09 20:42:03,695 [INFO] Instance 4: Cost = 6.7253, Routes = [[18, 0, 0, 0]]
2025-04-09 20:42:04,029 [INFO] Instance 5: Cost = 7.6776, Routes = [[9, 0, 0, 0]]
2025-04-09 20:42:37,873 [INFO] Evaluation completed. Mean reward: -7.0149
2025-04-09 20:42:37,874 [INFO] Final evaluation - Mean reward: -7.0149
2025-05-26 14:22:23,951 [INFO] Starting SVRP-RL with Namespace(num_nodes=20, num_vehicles=1, capacity=50.0, a_ratio=0.6, b_ratio=0.2, gamma_ratio=0.2, weather_dim=3, fixed_customers=False, embedding_dim=128, epochs=100, batch_size=32, lr=0.0001, baseline_lr=0.001, entropy_weight=0.01, max_steps=100, inference='beam', num_samples=16, beam_width=3, test_size=100, cuda=False, seed=42, save_dir='checkpoints', load_model=None, test=False, log_interval=10, save_interval=20, reoptimization=False)
2025-05-26 14:22:23,952 [INFO] Using device: cpu
2025-05-26 14:22:23,952 [INFO] Customer features dimension: 24
2025-05-26 14:22:23,952 [INFO] Vehicle features dimension: 2
2025-05-26 14:22:27,607 [INFO] Starting training for 100 epochs
2025-05-26 14:24:35,523 [INFO] Epoch 10/100 | Reward: -69.6718 | Policy Loss: -1698.0011 | Baseline Loss: 27483.0938 | Time: 13.05s
2025-05-26 14:46:48,287 [INFO] Starting SVRP-RL with Namespace(num_nodes=20, num_vehicles=1, capacity=50.0, a_ratio=0.6, b_ratio=0.2, gamma_ratio=0.2, weather_dim=3, fixed_customers=False, embedding_dim=128, epochs=100, batch_size=32, lr=0.0001, baseline_lr=0.001, entropy_weight=0.01, max_steps=100, inference='beam', num_samples=16, beam_width=3, test_size=100, cuda=False, seed=42, save_dir='checkpoints', load_model=None, test=False, log_interval=10, save_interval=20, reoptimization=False)
2025-05-26 14:46:48,288 [INFO] Using device: cpu
2025-05-26 14:46:48,288 [INFO] Customer features dimension: 24
2025-05-26 14:46:48,288 [INFO] Vehicle features dimension: 2
2025-05-26 14:46:51,373 [INFO] Starting training for 100 epochs
2025-05-26 15:04:00,926 [INFO] Starting SVRP-RL with Namespace(num_nodes=20, num_vehicles=1, capacity=50.0, a_ratio=0.6, b_ratio=0.2, gamma_ratio=0.2, weather_dim=3, fixed_customers=False, embedding_dim=128, epochs=100, batch_size=32, lr=0.0001, baseline_lr=0.001, entropy_weight=0.01, max_steps=100, inference='beam', num_samples=16, beam_width=3, test_size=100, cuda=False, seed=42, save_dir='checkpoints', load_model=None, test=False, log_interval=10, save_interval=20, reoptimization=False)
2025-05-26 15:04:00,927 [INFO] Using device: cpu
2025-05-26 15:04:00,927 [INFO] Customer features dimension: 24
2025-05-26 15:04:00,927 [INFO] Vehicle features dimension: 2
2025-05-26 15:04:04,275 [INFO] Starting training for 100 epochs
2025-05-26 15:45:08,221 [INFO] Starting SVRP-RL with Namespace(num_nodes=20, num_vehicles=1, capacity=50.0, a_ratio=0.6, b_ratio=0.2, gamma_ratio=0.2, weather_dim=3, fixed_customers=False, embedding_dim=128, epochs=100, batch_size=32, lr=0.0001, baseline_lr=0.001, entropy_weight=0.01, max_steps=100, inference='beam', num_samples=16, beam_width=3, test_size=100, cuda=False, seed=42, save_dir='checkpoints', load_model=None, test=False, log_interval=10, save_interval=20, reoptimization=False)
2025-05-26 15:45:08,221 [INFO] Using device: cpu
2025-05-26 15:45:08,221 [INFO] Customer features dimension: 24
2025-05-26 15:45:08,222 [INFO] Vehicle features dimension: 2
2025-05-26 15:45:10,499 [INFO] Starting training for 100 epochs
2025-05-26 16:20:09,195 [INFO] Starting SVRP-RL with Namespace(num_nodes=20, num_vehicles=1, capacity=50.0, a_ratio=0.6, b_ratio=0.2, gamma_ratio=0.2, weather_dim=3, fixed_customers=False, embedding_dim=128, epochs=100, batch_size=32, lr=0.0001, baseline_lr=0.001, entropy_weight=0.01, max_steps=100, inference='beam', num_samples=16, beam_width=3, test_size=100, cuda=False, seed=42, save_dir='checkpoints', load_model=None, test=False, log_interval=10, save_interval=20, reoptimization=False)
2025-05-26 16:20:09,196 [INFO] Using device: cpu
2025-05-26 16:20:09,196 [INFO] Customer features dimension: 24
2025-05-26 16:20:09,196 [INFO] Vehicle features dimension: 2
2025-05-26 16:20:11,228 [INFO] Starting training for 100 epochs
2025-05-26 16:31:06,823 [INFO] Starting SVRP-RL with Namespace(num_nodes=20, num_vehicles=1, capacity=50.0, a_ratio=0.6, b_ratio=0.2, gamma_ratio=0.2, weather_dim=3, fixed_customers=False, embedding_dim=128, epochs=100, batch_size=32, lr=0.0001, baseline_lr=0.001, entropy_weight=0.01, max_steps=100, inference='beam', num_samples=16, beam_width=3, test_size=100, cuda=False, seed=42, save_dir='checkpoints', load_model=None, test=False, log_interval=10, save_interval=20, reoptimization=False)
2025-05-26 16:31:06,823 [INFO] Using device: cpu
2025-05-26 16:31:06,823 [INFO] Customer features dimension: 24
2025-05-26 16:31:06,823 [INFO] Vehicle features dimension: 2
2025-05-26 16:31:08,537 [INFO] Starting training for 100 epochs
2025-05-26 16:37:08,253 [INFO] Starting SVRP-RL with Namespace(num_nodes=20, num_vehicles=1, capacity=50.0, a_ratio=0.6, b_ratio=0.2, gamma_ratio=0.2, weather_dim=3, fixed_customers=False, embedding_dim=128, epochs=100, batch_size=32, lr=0.0001, baseline_lr=0.001, entropy_weight=0.01, max_steps=100, inference='beam', num_samples=16, beam_width=3, test_size=100, cuda=False, seed=42, save_dir='checkpoints', load_model=None, test=False, log_interval=10, save_interval=20, reoptimization=False)
2025-05-26 16:37:08,254 [INFO] Using device: cpu
2025-05-26 16:37:08,254 [INFO] Customer features dimension: 24
2025-05-26 16:37:08,254 [INFO] Vehicle features dimension: 2
2025-05-26 16:38:32,808 [INFO] Starting SVRP-RL with Namespace(num_nodes=20, num_vehicles=1, capacity=50.0, a_ratio=0.6, b_ratio=0.2, gamma_ratio=0.2, weather_dim=3, fixed_customers=False, embedding_dim=128, epochs=100, batch_size=32, lr=0.0001, baseline_lr=0.001, entropy_weight=0.01, max_steps=100, inference='beam', num_samples=16, beam_width=3, test_size=100, cuda=False, seed=42, save_dir='checkpoints', load_model=None, test=False, log_interval=10, save_interval=20, reoptimization=False)
2025-05-26 16:38:32,808 [INFO] Using device: cpu
2025-05-26 16:38:32,808 [INFO] Customer features dimension: 24
2025-05-26 16:38:32,808 [INFO] Vehicle features dimension: 2
2025-05-26 16:38:34,704 [INFO] Starting training for 100 epochs
2025-05-26 16:39:55,412 [INFO] Epoch 10/100 | Reward: -72.8217 | Policy Loss: -1812.2709 | Baseline Loss: 30689.3828 | Time: 7.92s
2025-05-26 16:41:17,360 [INFO] Epoch 20/100 | Reward: -68.3876 | Policy Loss: -1388.3549 | Baseline Loss: 19520.0488 | Time: 9.96s
2025-05-26 16:41:17,374 [INFO] Saved model to checkpoints\model_epoch_20
2025-05-26 16:41:18,079 [INFO] Instance 1: Cost = 7.1914, Routes = [[12, 6, 19]]
2025-05-26 16:41:20,553 [INFO] Instance 2: Cost = 7.2208, Routes = [[3, 15, 10]]
2025-05-26 16:41:21,005 [INFO] Instance 3: Cost = 7.2309, Routes = [[2, 0, 6]]
2025-05-26 16:41:21,379 [INFO] Instance 4: Cost = 7.4391, Routes = [[12, 17, 8]]
2025-05-26 16:41:21,732 [INFO] Instance 5: Cost = 6.2926, Routes = [[18, 5, 0]]
2025-05-26 16:41:23,591 [INFO] Evaluation completed. Mean reward: -7.2002
2025-05-26 16:41:23,592 [INFO] Test reward: -7.2002
2025-05-26 16:42:50,803 [INFO] Epoch 30/100 | Reward: -71.2306 | Policy Loss: -936.7045 | Baseline Loss: 12098.8066 | Time: 8.40s
2025-05-26 16:44:18,145 [INFO] Epoch 40/100 | Reward: -70.0628 | Policy Loss: -125.7312 | Baseline Loss: 7622.6616 | Time: 8.60s
2025-05-26 16:44:18,161 [INFO] Saved model to checkpoints\model_epoch_40
2025-05-26 16:44:18,516 [INFO] Instance 1: Cost = 8.2027, Routes = [[0, 15, 2, 0]]
2025-05-26 16:44:19,192 [INFO] Instance 2: Cost = 7.4539, Routes = [[12, 4, 13]]
2025-05-26 16:44:19,524 [INFO] Instance 3: Cost = 7.4592, Routes = [[14, 18, 0]]
2025-05-26 16:44:19,849 [INFO] Instance 4: Cost = 7.3866, Routes = [[14, 6, 9]]
2025-05-26 16:44:20,202 [INFO] Instance 5: Cost = 8.0746, Routes = [[4, 10, 8, 0]]
2025-05-26 16:44:22,061 [INFO] Evaluation completed. Mean reward: -7.7959
2025-05-26 16:44:22,061 [INFO] Test reward: -7.7959
2025-05-26 16:45:47,913 [INFO] Epoch 50/100 | Reward: -69.6817 | Policy Loss: 15.1249 | Baseline Loss: 7238.5381 | Time: 8.30s
2025-05-26 16:47:13,791 [INFO] Epoch 60/100 | Reward: -70.0838 | Policy Loss: -354.3886 | Baseline Loss: 7608.1084 | Time: 9.00s
2025-05-26 16:47:13,796 [INFO] Saved model to checkpoints\model_epoch_60
2025-05-26 16:47:14,144 [INFO] Instance 1: Cost = 7.7523, Routes = [[6, 12, 17, 0]]
2025-05-26 16:47:14,757 [INFO] Instance 2: Cost = 7.8686, Routes = [[6, 9, 18, 0]]
2025-05-26 16:47:15,080 [INFO] Instance 3: Cost = 8.1344, Routes = [[5, 0, 0, 0]]
2025-05-26 16:47:15,424 [INFO] Instance 4: Cost = 8.0953, Routes = [[7, 0, 0, 0]]
2025-05-26 16:47:15,814 [INFO] Instance 5: Cost = 8.0233, Routes = [[17, 0, 0, 0]]
2025-05-26 16:47:17,539 [INFO] Evaluation completed. Mean reward: -7.9705
2025-05-26 16:47:17,539 [INFO] Test reward: -7.9705
2025-05-26 16:48:43,795 [INFO] Epoch 70/100 | Reward: -68.8106 | Policy Loss: -290.2531 | Baseline Loss: 7433.2412 | Time: 9.11s
2025-05-26 16:50:10,039 [INFO] Epoch 80/100 | Reward: -70.4812 | Policy Loss: -249.0603 | Baseline Loss: 7496.1133 | Time: 8.63s
2025-05-26 16:50:10,043 [INFO] Saved model to checkpoints\model_epoch_80
2025-05-26 16:50:10,366 [INFO] Instance 1: Cost = 7.7299, Routes = [[2, 0, 0, 0]]
2025-05-26 16:50:10,920 [INFO] Instance 2: Cost = 7.1053, Routes = [[12, 0, 0, 0]]
2025-05-26 16:50:11,237 [INFO] Instance 3: Cost = 7.1858, Routes = [[11, 0, 0, 0]]
2025-05-26 16:50:11,557 [INFO] Instance 4: Cost = 7.5562, Routes = [[7, 10, 0, 0]]
2025-05-26 16:50:11,943 [INFO] Instance 5: Cost = 6.7561, Routes = [[12, 15, 0, 0]]
2025-05-26 16:50:13,553 [INFO] Evaluation completed. Mean reward: -7.3154
2025-05-26 16:50:13,553 [INFO] Test reward: -7.3154
2025-05-26 16:51:35,582 [INFO] Epoch 90/100 | Reward: -72.4051 | Policy Loss: -359.5934 | Baseline Loss: 8468.4180 | Time: 8.03s
2025-05-26 16:53:01,407 [INFO] Epoch 100/100 | Reward: -73.2040 | Policy Loss: -425.2666 | Baseline Loss: 9832.5283 | Time: 8.94s
2025-05-26 16:53:01,413 [INFO] Saved model to checkpoints\model_epoch_100
2025-05-26 16:53:01,747 [INFO] Instance 1: Cost = 5.9236, Routes = [[15, 6, 0, 0]]
2025-05-26 16:53:02,375 [INFO] Instance 2: Cost = 6.3627, Routes = [[12, 0, 0, 0]]
2025-05-26 16:53:02,738 [INFO] Instance 3: Cost = 6.7781, Routes = [[5, 0, 0, 0]]
2025-05-26 16:53:03,075 [INFO] Instance 4: Cost = 7.1811, Routes = [[4, 0, 0, 0]]
2025-05-26 16:53:03,416 [INFO] Instance 5: Cost = 6.2470, Routes = [[10, 13, 0, 0]]
2025-05-26 16:53:05,243 [INFO] Evaluation completed. Mean reward: -6.6901
2025-05-26 16:53:05,243 [INFO] Test reward: -6.6901
2025-05-26 16:53:05,247 [INFO] Saved final model to checkpoints\model_final
2025-05-26 16:53:05,741 [INFO] Training completed
2025-05-26 16:53:05,742 [INFO] Evaluating model with beam inference strategy
2025-05-26 16:53:06,043 [INFO] Instance 1: Cost = 6.1477, Routes = [[15, 9, 0, 0]]
2025-05-26 16:53:06,713 [INFO] Instance 2: Cost = 6.6176, Routes = [[5, 19, 0, 0]]
2025-05-26 16:53:07,043 [INFO] Instance 3: Cost = 5.6801, Routes = [[17, 15, 0, 0]]
2025-05-26 16:53:07,372 [INFO] Instance 4: Cost = 6.2916, Routes = [[15, 6, 0, 0]]
2025-05-26 16:53:07,702 [INFO] Instance 5: Cost = 5.7516, Routes = [[9, 15, 0, 0]]
2025-05-26 16:53:41,522 [INFO] Evaluation completed. Mean reward: -6.4515
2025-05-26 16:53:41,522 [INFO] Final evaluation - Mean reward: -6.4515
2025-05-26 16:54:43,641 [INFO] Starting SVRP-RL with Namespace(num_nodes=20, num_vehicles=1, capacity=50.0, a_ratio=0.6, b_ratio=0.2, gamma_ratio=0.2, weather_dim=3, fixed_customers=False, embedding_dim=128, epochs=100, batch_size=32, lr=0.0001, baseline_lr=0.001, entropy_weight=0.01, max_steps=100, inference='beam', num_samples=16, beam_width=5, test_size=100, cuda=False, seed=42, save_dir='checkpoints', load_model='checkpoints/model_final', test=True, log_interval=10, save_interval=20, reoptimization=False)
2025-05-26 16:54:43,641 [INFO] Using device: cpu
2025-05-26 16:54:43,641 [INFO] Customer features dimension: 24
2025-05-26 16:54:43,642 [INFO] Vehicle features dimension: 2
2025-05-26 16:54:45,915 [INFO] Loaded model from checkpoints/model_final
2025-05-26 16:54:45,915 [INFO] Evaluating model with beam inference strategy
2025-05-26 16:54:46,273 [INFO] Instance 1: Cost = 2.9145, Routes = [[6]]
2025-05-26 16:54:47,070 [INFO] Instance 2: Cost = 2.8903, Routes = [[8]]
2025-05-26 16:54:47,427 [INFO] Instance 3: Cost = 2.9073, Routes = [[11]]
2025-05-26 16:54:47,830 [INFO] Instance 4: Cost = 2.9080, Routes = [[4]]
2025-05-26 16:54:48,314 [INFO] Instance 5: Cost = 2.9149, Routes = [[6]]
2025-05-26 16:55:18,570 [INFO] Evaluation completed. Mean reward: -2.9082
2025-05-26 16:55:18,570 [INFO] Final evaluation - Mean reward: -2.9082
2025-05-26 16:55:31,941 [INFO] Starting SVRP-RL with Namespace(num_nodes=20, num_vehicles=1, capacity=50.0, a_ratio=0.6, b_ratio=0.2, gamma_ratio=0.2, weather_dim=3, fixed_customers=False, embedding_dim=128, epochs=100, batch_size=32, lr=0.0001, baseline_lr=0.001, entropy_weight=0.01, max_steps=100, inference='beam', num_samples=16, beam_width=5, test_size=100, cuda=False, seed=42, save_dir='checkpoints', load_model='checkpoints/model_final', test=True, log_interval=10, save_interval=20, reoptimization=False)
2025-05-26 16:55:31,941 [INFO] Using device: cpu
2025-05-26 16:55:31,942 [INFO] Customer features dimension: 24
2025-05-26 16:55:31,942 [INFO] Vehicle features dimension: 2
2025-05-26 16:55:33,620 [INFO] Loaded model from checkpoints/model_final
2025-05-26 16:55:33,621 [INFO] Evaluating model with beam inference strategy
2025-05-26 16:55:33,928 [INFO] Instance 1: Cost = 2.9145, Routes = [[6]]
2025-05-26 16:55:34,820 [INFO] Instance 2: Cost = 2.8903, Routes = [[8]]
2025-05-26 16:55:35,132 [INFO] Instance 3: Cost = 2.9073, Routes = [[11]]
2025-05-26 16:55:35,442 [INFO] Instance 4: Cost = 2.9080, Routes = [[4]]
2025-05-26 16:55:35,802 [INFO] Instance 5: Cost = 2.9149, Routes = [[6]]
2025-05-26 16:56:05,603 [INFO] Evaluation completed. Mean reward: -2.9082
2025-05-26 16:56:05,603 [INFO] Final evaluation - Mean reward: -2.9082
2025-05-26 16:57:29,814 [INFO] Starting SVRP-RL with Namespace(num_nodes=20, num_vehicles=1, capacity=50.0, a_ratio=0.6, b_ratio=0.2, gamma_ratio=0.2, weather_dim=3, fixed_customers=True, embedding_dim=128, epochs=100, batch_size=32, lr=0.0001, baseline_lr=0.001, entropy_weight=0.01, max_steps=100, inference='beam', num_samples=16, beam_width=3, test_size=100, cuda=False, seed=42, save_dir='checkpoints', load_model=None, test=False, log_interval=10, save_interval=20, reoptimization=False)
2025-05-26 16:57:29,814 [INFO] Using device: cpu
2025-05-26 16:57:29,814 [INFO] Customer features dimension: 24
2025-05-26 16:57:29,815 [INFO] Vehicle features dimension: 2
2025-05-26 16:57:31,447 [INFO] Starting training for 100 epochs
2025-05-26 16:58:54,796 [INFO] Epoch 10/100 | Reward: -72.8217 | Policy Loss: -1812.2709 | Baseline Loss: 30689.3828 | Time: 8.69s
2025-05-26 17:00:20,076 [INFO] Epoch 20/100 | Reward: -68.3876 | Policy Loss: -1388.3549 | Baseline Loss: 19520.0488 | Time: 8.66s
2025-05-26 17:00:20,081 [INFO] Saved model to checkpoints\model_epoch_20
2025-05-26 17:00:20,404 [INFO] Instance 1: Cost = 7.1914, Routes = [[12, 6, 19]]
2025-05-26 17:00:21,084 [INFO] Instance 2: Cost = 7.2208, Routes = [[3, 15, 10]]
2025-05-26 17:00:21,427 [INFO] Instance 3: Cost = 7.2309, Routes = [[2, 0, 6]]
2025-05-26 17:00:21,769 [INFO] Instance 4: Cost = 7.4391, Routes = [[12, 17, 8]]
2025-05-26 17:00:22,091 [INFO] Instance 5: Cost = 6.2926, Routes = [[18, 5, 0]]
2025-05-26 17:00:23,823 [INFO] Evaluation completed. Mean reward: -7.2002
2025-05-26 17:00:23,823 [INFO] Test reward: -7.2002
2025-05-26 17:01:53,192 [INFO] Epoch 30/100 | Reward: -71.2306 | Policy Loss: -936.7045 | Baseline Loss: 12098.8066 | Time: 9.05s
2025-05-26 17:03:20,103 [INFO] Epoch 40/100 | Reward: -70.0628 | Policy Loss: -125.7312 | Baseline Loss: 7622.6616 | Time: 8.83s
2025-05-26 17:03:20,108 [INFO] Saved model to checkpoints\model_epoch_40
2025-05-26 17:03:20,460 [INFO] Instance 1: Cost = 8.2027, Routes = [[0, 15, 2, 0]]
2025-05-26 17:03:21,100 [INFO] Instance 2: Cost = 7.4539, Routes = [[12, 4, 13]]
2025-05-26 17:03:21,450 [INFO] Instance 3: Cost = 7.4592, Routes = [[14, 18, 0]]
2025-05-26 17:03:21,793 [INFO] Instance 4: Cost = 7.3866, Routes = [[14, 6, 9]]
2025-05-26 17:03:22,137 [INFO] Instance 5: Cost = 8.0746, Routes = [[4, 10, 8, 0]]
2025-05-26 17:03:23,921 [INFO] Evaluation completed. Mean reward: -7.7959
2025-05-26 17:03:23,922 [INFO] Test reward: -7.7959
