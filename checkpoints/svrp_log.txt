2025-04-09 19:22:55,608 [INFO] Starting SVRP-RL with Namespace(num_nodes=20, num_vehicles=1, capacity=50.0, a_ratio=0.6, b_ratio=0.2, gamma_ratio=0.2, weather_dim=3, fixed_customers=False, embedding_dim=128, epochs=100, batch_size=32, lr=0.0001, baseline_lr=0.001, entropy_weight=0.01, max_steps=100, inference='beam', num_samples=16, beam_width=3, test_size=100, cuda=False, seed=42, save_dir='checkpoints', load_model=None, test=False, log_interval=10, save_interval=20, reoptimization=False)
2025-04-09 19:22:55,609 [INFO] Using device: cpu
2025-04-09 19:22:55,609 [INFO] Customer features dimension: 24
2025-04-09 19:22:55,609 [INFO] Vehicle features dimension: 2
2025-04-09 19:22:57,881 [INFO] Starting training for 100 epochs
2025-04-09 19:24:23,744 [INFO] Epoch 10/100 | Reward: -69.6718 | Policy Loss: -1698.0011 | Baseline Loss: 27483.0938 | Time: 8.41s
2025-04-09 19:25:48,638 [INFO] Epoch 20/100 | Reward: -70.1642 | Policy Loss: -1425.5339 | Baseline Loss: 20595.0859 | Time: 8.34s
2025-04-09 19:25:48,658 [INFO] Saved model to checkpoints\model_epoch_20
2025-04-09 19:25:49,037 [INFO] Instance 1: Cost = 7.2346, Routes = [[12, 0, 7]]
2025-04-09 19:25:50,638 [INFO] Instance 2: Cost = 6.9318, Routes = [[12, 1, 11]]
2025-04-09 19:25:50,973 [INFO] Instance 3: Cost = 6.9959, Routes = [[12, 6, 7]]
2025-04-09 19:25:51,297 [INFO] Instance 4: Cost = 6.9491, Routes = [[3, 9, 6]]
2025-04-09 19:25:51,633 [INFO] Instance 5: Cost = 7.2100, Routes = [[3, 11, 19]]
2025-04-09 19:25:53,322 [INFO] Evaluation completed. Mean reward: -6.9788
2025-04-09 19:25:53,322 [INFO] Test reward: -6.9788
2025-04-09 19:27:20,262 [INFO] Epoch 30/100 | Reward: -70.6680 | Policy Loss: -855.2347 | Baseline Loss: 11686.9375 | Time: 8.47s
2025-04-09 19:28:44,850 [INFO] Epoch 40/100 | Reward: -72.6325 | Policy Loss: -140.6836 | Baseline Loss: 8591.2998 | Time: 8.36s
2025-04-09 19:28:44,867 [INFO] Saved model to checkpoints\model_epoch_40
2025-04-09 19:28:45,205 [INFO] Instance 1: Cost = 7.1705, Routes = [[18, 4, 8]]
2025-04-09 19:28:45,837 [INFO] Instance 2: Cost = 7.4493, Routes = [[4, 17, 12]]
2025-04-09 19:28:46,167 [INFO] Instance 3: Cost = 8.1978, Routes = [[13, 19, 6, 0]]
2025-04-09 19:28:46,502 [INFO] Instance 4: Cost = 7.4548, Routes = [[13, 5, 11]]
2025-04-09 19:28:46,841 [INFO] Instance 5: Cost = 7.3961, Routes = [[13, 17, 2]]
2025-04-09 19:28:48,484 [INFO] Evaluation completed. Mean reward: -7.4886
2025-04-09 19:28:48,484 [INFO] Test reward: -7.4886
2025-04-09 19:30:13,295 [INFO] Epoch 50/100 | Reward: -70.6034 | Policy Loss: -65.8344 | Baseline Loss: 8153.4746 | Time: 8.37s
2025-04-09 19:31:37,514 [INFO] Epoch 60/100 | Reward: -69.1068 | Policy Loss: -273.4041 | Baseline Loss: 6913.2886 | Time: 8.27s
2025-04-09 19:31:37,530 [INFO] Saved model to checkpoints\model_epoch_60
2025-04-09 19:31:37,868 [INFO] Instance 1: Cost = 8.0049, Routes = [[19, 0, 0, 0]]
2025-04-09 19:31:38,499 [INFO] Instance 2: Cost = 8.1171, Routes = [[17, 0, 0, 0]]
2025-04-09 19:31:38,875 [INFO] Instance 3: Cost = 7.9928, Routes = [[12, 0, 0, 0]]
2025-04-09 19:31:39,262 [INFO] Instance 4: Cost = 8.2004, Routes = [[16, 0, 0, 0]]
2025-04-09 19:31:39,614 [INFO] Instance 5: Cost = 8.0125, Routes = [[8, 7, 11, 0]]
2025-04-09 19:31:41,350 [INFO] Evaluation completed. Mean reward: -7.9800
2025-04-09 19:31:41,351 [INFO] Test reward: -7.9800
2025-04-09 19:33:19,312 [INFO] Epoch 70/100 | Reward: -70.2309 | Policy Loss: -292.4871 | Baseline Loss: 7233.0952 | Time: 10.52s
2025-04-09 19:34:53,281 [INFO] Epoch 80/100 | Reward: -71.0810 | Policy Loss: -210.1408 | Baseline Loss: 7615.4980 | Time: 9.07s
2025-04-09 19:34:53,286 [INFO] Saved model to checkpoints\model_epoch_80
2025-04-09 19:34:53,636 [INFO] Instance 1: Cost = 7.9715, Routes = [[6, 11, 0, 0]]
2025-04-09 19:34:54,313 [INFO] Instance 2: Cost = 7.7166, Routes = [[8, 0, 0, 0]]
2025-04-09 19:34:54,681 [INFO] Instance 3: Cost = 7.9501, Routes = [[7, 0, 0, 0]]
2025-04-09 19:34:55,054 [INFO] Instance 4: Cost = 7.6903, Routes = [[8, 0, 0, 0]]
2025-04-09 19:34:55,409 [INFO] Instance 5: Cost = 7.7613, Routes = [[7, 0, 0, 0]]
2025-04-09 19:34:57,184 [INFO] Evaluation completed. Mean reward: -7.8177
2025-04-09 19:34:57,184 [INFO] Test reward: -7.8177
2025-04-09 19:36:32,835 [INFO] Epoch 90/100 | Reward: -71.4202 | Policy Loss: -279.1256 | Baseline Loss: 7323.3359 | Time: 8.73s
2025-04-09 19:37:59,788 [INFO] Epoch 100/100 | Reward: -72.0833 | Policy Loss: -318.1506 | Baseline Loss: 7889.5171 | Time: 8.97s
2025-04-09 19:37:59,805 [INFO] Saved model to checkpoints\model_epoch_100
2025-04-09 19:38:00,188 [INFO] Instance 1: Cost = 6.8979, Routes = [[9, 10, 0, 0]]
2025-04-09 19:38:00,891 [INFO] Instance 2: Cost = 6.7242, Routes = [[15, 7, 0, 0]]
2025-04-09 19:38:01,227 [INFO] Instance 3: Cost = 7.6798, Routes = [[7, 0, 0, 0]]
2025-04-09 19:38:01,565 [INFO] Instance 4: Cost = 6.4743, Routes = [[9, 10, 0, 0]]
2025-04-09 19:38:01,907 [INFO] Instance 5: Cost = 6.8305, Routes = [[7, 0, 0, 0]]
2025-04-09 19:38:03,582 [INFO] Evaluation completed. Mean reward: -7.1242
2025-04-09 19:38:03,582 [INFO] Test reward: -7.1242
2025-04-09 19:38:03,586 [INFO] Saved final model to checkpoints\model_final
2025-04-09 19:38:04,118 [INFO] Training completed
2025-04-09 19:38:04,119 [INFO] Evaluating model with beam inference strategy
2025-04-09 19:38:04,424 [INFO] Instance 1: Cost = 6.6273, Routes = [[7, 0, 0, 0]]
2025-04-09 19:38:05,028 [INFO] Instance 2: Cost = 7.5872, Routes = [[5, 0, 0, 0]]
2025-04-09 19:38:05,372 [INFO] Instance 3: Cost = 7.5309, Routes = [[2, 0, 0, 0]]
2025-04-09 19:38:05,714 [INFO] Instance 4: Cost = 7.4230, Routes = [[0, 0, 0, 0]]
2025-04-09 19:38:06,052 [INFO] Instance 5: Cost = 7.1605, Routes = [[5, 0, 0, 0]]
2025-04-09 19:38:38,020 [INFO] Evaluation completed. Mean reward: -7.0835
2025-04-09 19:38:38,021 [INFO] Final evaluation - Mean reward: -7.0835
2025-04-09 20:41:59,024 [INFO] Starting SVRP-RL with Namespace(num_nodes=20, num_vehicles=1, capacity=50.0, a_ratio=0.6, b_ratio=0.2, gamma_ratio=0.2, weather_dim=3, fixed_customers=False, embedding_dim=128, epochs=100, batch_size=32, lr=0.0001, baseline_lr=0.001, entropy_weight=0.01, max_steps=100, inference='beam', num_samples=16, beam_width=3, test_size=100, cuda=False, seed=42, save_dir='checkpoints', load_model='checkpoints/model_final', test=True, log_interval=10, save_interval=20, reoptimization=False)
2025-04-09 20:41:59,025 [INFO] Using device: cpu
2025-04-09 20:41:59,025 [INFO] Customer features dimension: 24
2025-04-09 20:41:59,025 [INFO] Vehicle features dimension: 2
2025-04-09 20:42:01,634 [INFO] Loaded model from checkpoints/model_final
2025-04-09 20:42:01,634 [INFO] Evaluating model with beam inference strategy
2025-04-09 20:42:02,075 [INFO] Instance 1: Cost = 6.8610, Routes = [[9, 6, 0, 0]]
2025-04-09 20:42:03,005 [INFO] Instance 2: Cost = 7.6485, Routes = [[0, 0, 0, 0]]
2025-04-09 20:42:03,352 [INFO] Instance 3: Cost = 6.7028, Routes = [[18, 7, 0, 0]]
2025-04-09 20:42:03,695 [INFO] Instance 4: Cost = 6.7253, Routes = [[18, 0, 0, 0]]
2025-04-09 20:42:04,029 [INFO] Instance 5: Cost = 7.6776, Routes = [[9, 0, 0, 0]]
2025-04-09 20:42:37,873 [INFO] Evaluation completed. Mean reward: -7.0149
2025-04-09 20:42:37,874 [INFO] Final evaluation - Mean reward: -7.0149
